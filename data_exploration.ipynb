{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from utils import check_accuracy_classification\n",
    "import transformers\n",
    "from torch.optim import Adam\n",
    "from models import BertProbeClassifer\n",
    "from utils import text_to_dataloader, tokenize_word\n",
    "from bert_embedding import BertEmbeddingExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(\"data\",\"en_partut-ud-train.conllu\")\n",
    "dev_path = os.path.join(\"data\",\"en_partut-ud-dev.conllu\")\n",
    "test_path = os.path.join(\"data\",\"en_partut-ud-test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_CONST = \"# sent_id = \"\n",
    "TEXT_CONST = \"# text = \"\n",
    "STOP_CONST = \"\\n\"\n",
    "WORD_OFFSET = 1\n",
    "LABEL_OFFSET = 3\n",
    "\n",
    "\n",
    "def txt_to_dataframe(data_path):\n",
    "    '''\n",
    "    read UD text file and convert to df format\n",
    "    '''\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        df = pd.DataFrame(\n",
    "            columns={\n",
    "                \"text\",\n",
    "                \"word\",\n",
    "                \"label\"\n",
    "            }\n",
    "        )\n",
    "        for line in fp.readlines():\n",
    "            if TEXT_CONST in line:\n",
    "                words_list = []\n",
    "                labels_list = []\n",
    "                text = line.split(TEXT_CONST)[1]\n",
    "                # this is a new text, need to parse all the words in it\n",
    "            elif line is not STOP_CONST and HEADER_CONST not in line:\n",
    "                temp_list = line.split(\"\\t\")\n",
    "                words_list.append(temp_list[WORD_OFFSET])\n",
    "                labels_list.append(temp_list[LABEL_OFFSET])\n",
    "            if line == STOP_CONST:\n",
    "                # this is the end of the text, adding to df\n",
    "                cur_df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"text\": len(words_list) * [text],\n",
    "                        \"word\": words_list,\n",
    "                        \"label\": labels_list\n",
    "                    }\n",
    "                )\n",
    "                df = pd.concat([df,cur_df])\n",
    "        return df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = txt_to_dataframe(train_path)\n",
    "df_dev = txt_to_dataframe(dev_path)\n",
    "df_test = txt_to_dataframe(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\n",
    "    \"ADJ\",\n",
    "    \"ADP\",\n",
    "    \"ADV\",\n",
    "    \"AUX\",\n",
    "    \"CCONJ\",\n",
    "    \"DET\",\n",
    "    \"INTJ\",\n",
    "    \"NOUN\",\n",
    "    \"NUM\",\n",
    "    \"PART\",\n",
    "    \"PRON\",\n",
    "    \"PROPN\",\n",
    "    \"PUNCT\",\n",
    "    \"SCONJ\",\n",
    "    \"SYM\",\n",
    "    \"VERB\",\n",
    "    \"X\",\n",
    "    \"_\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'tex_artifacts/label_dist_train.tex'\n",
    "SORT_COL = \"Count\"\n",
    "\n",
    "with open(file_name,'w') as tf:\n",
    "    display_df = df_train[\"label\"].value_counts().rename_axis(\"Type\").to_frame(\"Count\").reset_index()\n",
    "    #display_df.index = TYPES\n",
    "    display_df.sort_values(by=SORT_COL, inplace=True, ascending=False)\n",
    "    latex_data = display_df.to_latex(index=False)\n",
    "    tf.write(latex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'tex_artifacts/label_dist_dev.tex'\n",
    "\n",
    "\n",
    "with open(file_name,'w') as tf:\n",
    "    display_df = df_dev[\"label\"].value_counts().rename_axis(\"Type\").to_frame(\"Count\").reset_index()\n",
    "    #display_df.index = TYPES\n",
    "    display_df.sort_values(by=\"Type\", inplace=True)\n",
    "    latex_data = display_df.to_latex(index=False)\n",
    "    tf.write(latex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'tex_artifacts/label_dist_test.tex'\n",
    "\n",
    "\n",
    "with open(file_name,'w') as tf:\n",
    "    display_df = df_test[\"label\"].value_counts().rename_axis(\"Type\").to_frame(\"Count\").reset_index()\n",
    "    #display_df.index = TYPES\n",
    "    display_df.sort_values(by=\"Type\", inplace=True)\n",
    "    latex_data = display_df.to_latex(index=False)\n",
    "    tf.write(latex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Any use of the work other than as authorized u...</td>\n",
       "      <td>authorized</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Any use of the work other than as authorized u...</td>\n",
       "      <td>prohibited</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNLESS OTHERWISE AGREED TO BY THE PARTIES IN W...</td>\n",
       "      <td>AGREED</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UNLESS OTHERWISE AGREED TO BY THE PARTIES IN W...</td>\n",
       "      <td>OFFERS</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UNLESS OTHERWISE AGREED TO BY THE PARTIES IN W...</td>\n",
       "      <td>IS</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In the 18th and 19th centuries, his reputation...</td>\n",
       "      <td>spread</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Only a small minority of academics believe the...</td>\n",
       "      <td>believe</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Only a small minority of academics believe the...</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Only a small minority of academics believe the...</td>\n",
       "      <td>question</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Only a small minority of academics believe the...</td>\n",
       "      <td>continues</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text        word label\n",
       "8   Any use of the work other than as authorized u...  authorized  VERB\n",
       "16  Any use of the work other than as authorized u...  prohibited  VERB\n",
       "2   UNLESS OTHERWISE AGREED TO BY THE PARTIES IN W...      AGREED  VERB\n",
       "11  UNLESS OTHERWISE AGREED TO BY THE PARTIES IN W...      OFFERS  VERB\n",
       "16  UNLESS OTHERWISE AGREED TO BY THE PARTIES IN W...          IS  VERB\n",
       "..                                                ...         ...   ...\n",
       "12  In the 18th and 19th centuries, his reputation...      spread  VERB\n",
       "6   Only a small minority of academics believe the...     believe  VERB\n",
       "8   Only a small minority of academics believe the...          is  VERB\n",
       "11  Only a small minority of academics believe the...    question  VERB\n",
       "30  Only a small minority of academics believe the...   continues  VERB\n",
       "\n",
       "[326 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test[\"label\"] == \"VERB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, dataloader_train = text_to_dataloader(df_train, \"cuda\", 32, bert_tokenizer, 256)\n",
    "df_test, dataloader_test = text_to_dataloader(df_test, \"cuda\", 32, bert_tokenizer, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'tex_artifacts/tokens_per_word_dist_train.tex'\n",
    "\n",
    "INDEX_AXIS_NAME = \"Tokens/Word\"\n",
    "SORT_COL = \"Tokens/Word\"\n",
    "\n",
    "with open(file_name,'w') as tf:\n",
    "    display_df = df_train[\"query_mask\"].apply(lambda x: sum(x)).value_counts().rename_axis(INDEX_AXIS_NAME).to_frame(\"Count\").reset_index()\n",
    "    display_df.sort_values(by=SORT_COL, inplace=True)\n",
    "    latex_data = display_df.to_latex(index=False)\n",
    "    tf.write(latex_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label_idx</th>\n",
       "      <th>embedding</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30137</th>\n",
       "      <td>and</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.15574118, 1.0346084, 0.5065768, 0.45339814,...</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17961</th>\n",
       "      <td>the</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.28361148, -0.43603727, 0.08641514, 0.36970...</td>\n",
       "      <td>DET</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39003</th>\n",
       "      <td>shakespeare</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.06348628, -0.30637914, 0.92618424, -0.28851...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32187</th>\n",
       "      <td>his</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.39322716, 0.4311395, 0.48470542, 0.2271323...</td>\n",
       "      <td>DET</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32078</th>\n",
       "      <td>had</td>\n",
       "      <td>15</td>\n",
       "      <td>[-1.1276822, 0.06973337, -0.034231067, -0.3327...</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13290</th>\n",
       "      <td>it</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.1944471, 0.23595017, -0.3196561, -0.541352...</td>\n",
       "      <td>PRON</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22870</th>\n",
       "      <td>economy</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.036572564, 0.16637069, 0.23336361, 0.303162...</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>when</td>\n",
       "      <td>13</td>\n",
       "      <td>[-1.1226387, 0.61780995, -0.021228101, 0.22293...</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19222</th>\n",
       "      <td>the</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.17872518, 0.046215557, 0.056803722, 0.0912...</td>\n",
       "      <td>DET</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23037</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.3867881, 0.8922424, -0.4306744, -0.8759147...</td>\n",
       "      <td>ADP</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  label_idx  \\\n",
       "30137          and          4   \n",
       "17961          the          5   \n",
       "39003  shakespeare         11   \n",
       "32187          his          5   \n",
       "32078          had         15   \n",
       "13290           it         10   \n",
       "22870      economy          7   \n",
       "3224          when         13   \n",
       "19222          the          5   \n",
       "23037           in          1   \n",
       "\n",
       "                                               embedding  label  \\\n",
       "30137  [0.15574118, 1.0346084, 0.5065768, 0.45339814,...  CCONJ   \n",
       "17961  [-0.28361148, -0.43603727, 0.08641514, 0.36970...    DET   \n",
       "39003  [0.06348628, -0.30637914, 0.92618424, -0.28851...  PROPN   \n",
       "32187  [-0.39322716, 0.4311395, 0.48470542, 0.2271323...    DET   \n",
       "32078  [-1.1276822, 0.06973337, -0.034231067, -0.3327...   VERB   \n",
       "13290  [-0.1944471, 0.23595017, -0.3196561, -0.541352...   PRON   \n",
       "22870  [0.036572564, 0.16637069, 0.23336361, 0.303162...   NOUN   \n",
       "3224   [-1.1226387, 0.61780995, -0.021228101, 0.22293...  SCONJ   \n",
       "19222  [-0.17872518, 0.046215557, 0.056803722, 0.0912...    DET   \n",
       "23037  [-0.3867881, 0.8922424, -0.4306744, -0.8759147...    ADP   \n",
       "\n",
       "      embedding_shape  \n",
       "30137          (768,)  \n",
       "17961          (768,)  \n",
       "39003          (768,)  \n",
       "32187          (768,)  \n",
       "32078          (768,)  \n",
       "13290          (768,)  \n",
       "22870          (768,)  \n",
       "3224           (768,)  \n",
       "19222          (768,)  \n",
       "23037          (768,)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df_9.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1356/1356 [06:41<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 9\n",
    "\n",
    "\n",
    "bex_9 = BertEmbeddingExtractor(num_hidden_layers, \"bert-base-uncased\")\n",
    "embedding_df_9 = bex_9.extract_embedding(dataloader_train, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1356/1356 [06:40<00:00,  3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 4\n",
    "\n",
    "\n",
    "bex_4 = BertEmbeddingExtractor(num_hidden_layers, \"bert-base-uncased\")\n",
    "embedding_df_4 = bex_9.extract_embedding(dataloader_train, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# query_df = embedding_df_4\n",
    "query_df = embedding_df_9\n",
    "\n",
    "contextual_embedding_array = np.vstack(query_df[\"embedding\"].values)\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "lower_dim_data = reducer.fit_transform(\n",
    "    contextual_embedding_array,\n",
    "    y=query_df[\"label_idx\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import cm\n",
    "import mplcursors\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "word_list = list(query_df[\"word\"].tolist())\n",
    "all_labels = query_df[\"label\"].tolist()\n",
    "labels = list(set(all_labels))\n",
    "labels.sort()\n",
    "n_colors = len(labels)\n",
    "\n",
    "\n",
    "#create new colormap\n",
    "cmap = cm.get_cmap('tab20', n_colors)\n",
    "\n",
    "\n",
    "print(n_colors)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "sc = plt.scatter(\n",
    "    lower_dim_data[:,0], \n",
    "    lower_dim_data[:,1], \n",
    "    c=query_df[\"label_idx\"].tolist(),\n",
    "    cmap=cmap,\n",
    "    s=1\n",
    ")\n",
    "\n",
    "# cursor\n",
    "crs = mplcursors.cursor(ax,hover=True)\n",
    "crs.connect(\n",
    "    \"add\", \n",
    "    lambda sel: sel.annotation.set_text(\n",
    "        f\"{word_list[sel.target.index]}\\n{all_labels[sel.target.index]}\"\n",
    "    ))\n",
    "    \n",
    "\n",
    "# colorbar\n",
    "c_ticks = np.arange(n_colors) * (n_colors / (n_colors + 1)) + (2 / n_colors)\n",
    "cbar = plt.colorbar(sc, ticks=c_ticks)\n",
    "#cbar = plt.colorbar()\n",
    "\n",
    "ticklabs = cbar.ax.get_yticklabels()\n",
    "cbar.ax.set_yticklabels(labels, ha=\"right\")\n",
    "cbar.ax.yaxis.set_tick_params(pad=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(display_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1170px",
    "left": "51px",
    "right": "20px",
    "top": "119px",
    "width": "559px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
